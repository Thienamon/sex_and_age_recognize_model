{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 이전에 학습된 모델과 같은 계층 구조와 변수들을 가진 클래스\n",
    "# 이 클래스로 그래프를 만들고 거기에 각 변수를 읽어와서 대입함\n",
    "class Model:\n",
    "    def __init__(self, sess, name):\n",
    "        self.name = name\n",
    "        self._build_net()\n",
    "        self.saver = tf.Saver()\n",
    "        self.sess = sess\n",
    "    \n",
    "    def _build_net(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            self.training = tf.placeholder(tf.bool)\n",
    "            \n",
    "            # input place holders\n",
    "            self.X = tf.placeholder(tf.float32, [None, 80, 55, 1])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, 3])\n",
    "            \n",
    "            # Convolution Layer 1 and Pooling Layer 1\n",
    "            conv1 = tf.layers.conv2d(\n",
    "                inputs = self.X,\n",
    "                filters = 32,\n",
    "                kernel_size = [3, 3],\n",
    "                padding = 'SAME',\n",
    "                activation = tf.nn.relu)\n",
    "            pool1 = tf.layers.max_pooling2d(\n",
    "                inputs = conv1,\n",
    "                pool_size = [2, 2],\n",
    "                strides = 2,\n",
    "                padding = 'SAME')\n",
    "            dropout1 = tf.layers.dropout(\n",
    "                inputs = pool1,\n",
    "                rate = 0.7,\n",
    "                training = self.training)\n",
    "            \n",
    "            # Convolution Layer 2 and Pooling Layer 2\n",
    "            conv2 = tf.layers.conv2d(\n",
    "                inputs = dropout1, \n",
    "                filters = 64,\n",
    "                kernel_size = [3, 3],\n",
    "                padding = 'SAME',\n",
    "                activation = tf.nn.relu)\n",
    "            pool2 = tf.layers.max_pooling2d(\n",
    "                inputs = conv2,\n",
    "                pool_size = [2, 2],\n",
    "                strides = 2,\n",
    "                padding = 'SAME')\n",
    "            dropout2 = tf.layers.dropout(\n",
    "                inputs = pool2,\n",
    "                rate = 0.7,\n",
    "                training = self.training)\n",
    "            \n",
    "            # Dense Layer\n",
    "            flat = tf.reshape(dropout2, [-1, 20 * 14 * 64])\n",
    "            dense4 = tf.layers.dense(\n",
    "                inputs = flat,\n",
    "                units = 512,\n",
    "                activation = tf.nn.relu)\n",
    "            dropout4 = tf.layers.dropout(\n",
    "                inputs = dense4,\n",
    "                rate = 0.5,\n",
    "                training = self.training)\n",
    "\n",
    "            # Logits Layer (FC 1024 inputs -> 3 outputs)\n",
    "            self.logits = tf.layers.dense(\n",
    "                inputs = dropout4,\n",
    "                units = 3)\n",
    "\n",
    "        # Define cost, optimizer\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = self.logits, labels = self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(self.cost)\n",
    "        \n",
    "        correct_pred = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "        self.acc = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        \n",
    "    def predict(self, x_test, training = False):\n",
    "        return self.sess.run(\n",
    "            self.logits,\n",
    "            feed_dict = {self.X: x_test, self.training: training})\n",
    "\n",
    "    def get_accuracy(self, x_test, y_test, training = False):\n",
    "        return self.sess.run(\n",
    "            self.acc,\n",
    "            feed_dict = {self.X: x_test, self.Y: y_test, self.training: training})\n",
    "\n",
    "    def train(self, x_data, y_data, training = True):\n",
    "        return self.sess.run(\n",
    "            [self.cost, self.optimizer],\n",
    "            feed_dict = {self.X: x_data, self.Y: y_data, self.training: training})\n",
    "    \n",
    "    def save(self, path):\n",
    "        self.saver.save(sess=self.sess, save_path=path+self.name)\n",
    "\n",
    "    def load(self, path):\n",
    "        self.saver.restore(self.sess, path+self.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 저장 경로를 위한 함수\n",
    "def get_path(num):\n",
    "    dirt = path+str(num)+'/'\n",
    "    if not os.path.exists(dirt):\n",
    "        os.makedirs(dirt)\n",
    "    return dirt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "# 모델 로드\n",
    "models = []\n",
    "num_models = 5\n",
    "for m in range(num_models):\n",
    "    models.append(Model.Model(sess, \"model\" + str(m)))\n",
    "    save_dir = get_path(m)\n",
    "    models[m].load(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if len(sys.argv)>1:\n",
    "    data_path = sys.argv[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 파일을 어떻게 넘겨올까 조금 더 생각해봐야\n",
    "size = len(data)\n",
    "predictions = np.zeros(size * 3).reshape(size, 3)\n",
    "for m_idx, m in enumerate(models):\n",
    "    p = m.predict(data)\n",
    "    predictions += p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
